from utils.config import parse_args
from utils.data.loader import get_data_loader
from models.nk_model import nkModel
import torch
from utils.engine import train, val
from torch.utils.tensorboard import SummaryWriter

def main(args):

    summary = SummaryWriter(args.summary_location)
    train_loader, val_loader = get_data_loader(args)
    model = nkModel()

    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)

    # 모델 불러오기
    if args.load_model:
        location = args.load_model_location
        print("load model : ", location)
        checkpoint = torch.load(location)
        model.load_state_dict(checkpoint['model_state-dict'])

    # 학습을 몇번 시킬지 결정
    for epoch in range(args.start_epoch, args.max_epoch):
        train(model, train_loader, optimizer, epoch, summary) # 학습
        val(model, val_loader, epoch, summary) # 평가 (optimizer X - 최적화를 할 필요가 없음)
        if epoch % args.save_freq == 0:
            torch.save({
                'epoch':epoch,
                'model_state_dict':model.state_dict(),
                "optimizer":optimizer.state_dict()
            }, args.save_location + '/save_model/selectTF_model_{}.pth'.format(epoch))

if __name__ == '__main__':
    config = parse_args()
    main(config)
