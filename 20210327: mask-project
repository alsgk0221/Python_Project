import streamlit as st
from PIL import Image, ImageOps
import numpy as np
import cv2
import torch
import torchvision
import torch.nn as nn


model = torchvision.models.vgg11(pretrained=True)
model.fc = nn.Linear(512, 2)
model.load_state_dict(torch.load("model_127.pth", map_location=torch.device('cpu')))

def model_predict(image, model):
    model.eval()

    size = (256, 256)

    image = ImageOps.fit(image, size, Image.ANTIALIAS)
    image = np.asarray(image).astype(np.float32)

    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    img_resize = (cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)) / 255.
    img_resize = torch.tensor(img_resize)
    img_resize = img_resize.permute(2, 0, 1)
    img_resize = img_resize.unsqueeze(0)

    predict = model(img_resize)
    values, label = torch.topk(predict, k = 1)
    if label == 0:
        st.write("masked")
    else:
        st.write("un-masked")


st.write("Test code")
file = st.file_uploader("Upload an image file!", type=["jpg", "png"])

if file is None:
    st.text("Upload an image file!")
else:
    img = Image.open(file)
    st.image(img, use_column_width=True)
    model = model.float()
    model_predict(img, model)
    
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
import os
from torch.utils.data.dataset import Dataset
from torchvision import transforms
import torch
import cv2

total = 0
f = open('label.txt', 'w')
masked_file = 0
face_file = 0

for (path, dir, files) in os.walk("./self-built-masked-face-recognition-dataset"):
    for filename in files:
        ext = os.path.splitext(filename)[-1]
        if ext == ".jpg":
            total_file_name = path + '/' + filename
            if 'AFDB_masked' in total_file_name:
                masked_file +=1
                f.write(', 1 \n')
            else:
                face_file += 1
                if face_file > 2200:
                    break
                f.write(', 0 \n')

print(masked_file, face_file)

print("un-masked face file : ", face_file)
print("masked face file : ", masked_file)



class customDataset(Dataset):

    def __init__(self, file_path):

        self.trans = transforms.Compose([transforms.RandomHorizontalFlip(),
                                         transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                                              std=[0.229, 0.224, 0.225])])
        self.to_tensor = transforms.ToTensor()
        f = open("text", 'r')
        total_line = f.readlines()

        self.img_path = []
        self.label_list = []
        for i in range(len(total_line)):
            img = total_line[i].split(',')[0]
            self.img_path.append(img)

            self.label_list.append(total_line[i].split(',')[1].strip('\n'))
        self.data_len = len(self.label_list)

    def __getitem__(self, index):

        img = cv2.imread(self.img_path[index])
        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA)
        img = self.to_tensor(img)
        label = float(self.label_list[index])

        return img, label

    def __len__(self):
        return self.data_len

def get_data_loader():

    path = "test"
    custom_dataset = customDataset(path)
    train_loader = torch.utils.data.DataLoader(dataset=custom_dataset, batch_size=10, shuffle=False)
    return train_loader
